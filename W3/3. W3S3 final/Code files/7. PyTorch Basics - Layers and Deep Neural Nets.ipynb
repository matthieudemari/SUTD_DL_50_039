{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. PyTorch Basics - Layers and Deep Neural Nets\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.3 (09/02/2025)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.13.1)\n",
    "- Matplotlib (tested on v3.10.0)\n",
    "- Numpy (tested on v2.2.1)\n",
    "- Pandas (tested on v2.2.3\n",
    "- Torch (tested on v2.7.0+cu124)\n",
    "- Torchvision (tested on v0.22.0+cu124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Time\n",
    "from time import time\n",
    "# Torch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most typical multi-label classification task: the MNIST dataset\n",
    "\n",
    "MNIST is a widely-used dataset for the benchmarking of machine learning and computer vision algorithms. It consists of a training set of 60,000 examples and a test set of 10,000 examples. All samples consist of 28x28 pixel grayscale images of handwritten digits (0 to 9).\n",
    "\n",
    "MNIST is often used as a \"Hello, World!\" example for machine learning and deep learning, due to its simplicity and the availability of efficient implementations of various learning algorithms. It is a good dataset to use for testing and comparing the performance of different models, as well as for getting familiar with the basics of machine learning and deep learning.\n",
    "\n",
    "The images serve as inputs, and the task is therefore to predict which of the ten digits appears in the image. This is therefore a classification task, like before, except that it consists of 10 differents classes (0-9) instead of just two like in binary classification.\n",
    "\n",
    "In addition, note that in general, it is good to do the following:\n",
    "- Scale the data (pixel values) to the [0,1] range.\n",
    "- Normalize the data to have zero mean and unit standard deviation.\n",
    "\n",
    "We will then subtract a mean of 0.1307 and divide by a standard deviation of 0.3081. \n",
    "These values are basically the mean and the standard deviation of the dataset divided by 255 (original max pixel value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:02<00:00, 4.56MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 118kB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:03<00:00, 456kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 11.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define transform to convert images to tensors and normalize them\n",
    "transform_data = Compose([ToTensor(),\n",
    "                          Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the data\n",
    "batch_size = 256\n",
    "train_dataset = MNIST(root = './mnist/', train = True, download = True, transform = transform_data)\n",
    "test_dataset = MNIST(root = './mnist/', train = False, download = True, transform = transform_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Batch number:  0\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Try the dataloader\n",
    "for batch_number, batch in enumerate(train_loader):\n",
    "    inputs, outputs = batch\n",
    "    print(\"---\")\n",
    "    print(\"Batch number: \", batch_number)\n",
    "    print(inputs.shape)\n",
    "    print(outputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-classification and softmax predictions\n",
    "\n",
    "In binary classification, we would produce a single value $ p $ as output, with value between 0 and 1. This value would correspond to the probability of being of class 1, and the probability of being of class 0 would then simply be $ 1 - p $. We would then use a threshold 0.5 to decide if the sample is of class 0 or 1 and call that the prediction of the model.\n",
    "\n",
    "Unfortunately, when we have more than 2 classes, we can no longer rely on a single output value $ p $. Instead it is often preferable to have the model output 10 values: $ (p_0, p_1, p_2, ... p_9) $, where each $ p_i $ corresponds to the probability of being of class $ i $. \n",
    "\n",
    "This could typically be done by asking for the final layer to produce n_y = 10 values instead of just 1.\n",
    "\n",
    "Unfortunately, this is not good enough: the $ p_i $ are probabilities and their sum should be equal to 1, i.e.\n",
    "\n",
    "$$ \\sum_{i=0}^9 p_i = 1. $$\n",
    "\n",
    "A fully connected layer is not smart enough to do that on its own: it might produce negative values and these values may not sum up to 1.\n",
    "\n",
    "To normalize the outputs produced by the final fully connected layer, we will use the softmax operation, which is a special activation function, whose objective is to transform a vector of $ N $ values $ Y = (y_0, y_1, y_2, ... y_9) $, into another vector of $ N $ values $ P = (p_0, p_1, p_2, ... p_9) $, this time summing up to 1.\n",
    "\n",
    "The softmax operation $ p_i = s(y_i, Y) $ is defined as:\n",
    "\n",
    "$$ \\forall i, p_i = s(y_i, Y) = \\frac{exp(y_i)}{\\sum_{k=0}^9 exp(y_k)}. $$\n",
    "\n",
    "We show an implementation of the softmax operation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # Subtract the maximum value from each element of the input vector x\n",
    "    # to avoid numerical instability (this is optional, but equivalent)\n",
    "    x = x - np.max(x)\n",
    "    # Compute the exponent of each element\n",
    "    exp_x = np.exp(x)\n",
    "    # Normalize the exponentiated values by their sum\n",
    "    return exp_x/np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45\n",
      "[0.08089815 0.10387528 0.14021696 0.10920108 0.12068586 0.08940628\n",
      " 0.10387528 0.0769527  0.08089815 0.09399024]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Ten values that do not sum up to 1\n",
    "Y = np.array([-1, 4, 10, 5, 7, 1, 4, -2, -1, 2])/20\n",
    "print(sum(Y))\n",
    "P = softmax(Y)\n",
    "print(P)\n",
    "print(np.sum(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(list(range(10)), Y, \"r--\", label = \"Before softmax\")\n",
    "plt.plot(list(range(10)), P, \"b--\", label = \"After softmax\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of multi-label classification, we will use the softmax operation as the final operation after the last fully connected layer. This will produce a vector of 10 values, $ P = (p_0, p_1, p_2, ... p_9) $, corresponding to the probability of being of each class $ i $.\n",
    "\n",
    "The predicted class $ pred $ will then be the index of the highest $ p_i $ value, i.e.\n",
    "\n",
    "$$ pred = \\arg\\max_i [p_i]. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Shallow Neural Network with torch.nn.Linear\n",
    "\n",
    "Below is a simple implementation of a shallow neural network.\n",
    "\n",
    "To make its implementation simpler, we will replace the typical $ Wx + b $ operation, by its equivalent in PyTorch, which is the torch.nn.Linear() one (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
    "\n",
    "This will simplify the code in our init method, as we no longer have to specify them explicitly by doing this:\n",
    "\n",
    "```\n",
    "self.W1 = torch.nn.Parameter(torch.randn(n_x, n_h, requires_grad = True, \\\n",
    "                             dtype = torch.float64, device = device)*0.1)\n",
    "self.b1 = torch.nn.Parameter(torch.randn(1, n_h, requires_grad = True, \\\n",
    "                             dtype = torch.float64, device = device)*0.1)\n",
    "self.W2 = torch.nn.Parameter(torch.randn(n_h, n_y, requires_grad = True, \\\n",
    "                             dtype = torch.float64, device = device)*0.1)\n",
    "self.b2 = torch.nn.Parameter(torch.randn(1, n_y, requires_grad = True, \\\n",
    "                             dtype = torch.float64, device = device)*0.1)\n",
    "self.W1.retain_grad()\n",
    "self.b1.retain_grad()\n",
    "self.W2.retain_grad()\n",
    "self.b2.retain_grad()\n",
    "```\n",
    "\n",
    "We simply rewrite this as two nn.Linear() layers, stored in two attributes.\n",
    "\n",
    "```\n",
    "self.fc1 = torch.nn.Linear(n_x, n_h)\n",
    "self.fc2 = torch.nn.Linear(n_h, n_y)\n",
    "```\n",
    "\n",
    "We can then simply replace the operations in the forward method to make it simpler:\n",
    "\n",
    "```\n",
    "Z1 = torch.matmul(inputs, self.W1)\n",
    "Z1_b = Z1 + self.b1\n",
    "```\n",
    "\n",
    "It simply becomes:\n",
    "\n",
    "```\n",
    "x = self.fc1(x)\n",
    "```\n",
    "\n",
    "The adaptation of our Shallow Neural Network class for multi-label classification is then shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_y):\n",
    "        super().__init__()\n",
    "        # Define two layers using the nn.Linear()\n",
    "        self.fc1 = torch.nn.Linear(n_x, n_h)\n",
    "        self.fc2 = torch.nn.Linear(n_h, n_y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten images (transform them from 28x28 2D\n",
    "        # matrices to 784 1D vectors)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # First Wx + b operation\n",
    "        out1 = self.fc1(x)\n",
    "        # Using ReLU operation as activation after first layer\n",
    "        act1 = torch.relu(out1)\n",
    "        # Second Wx + b operation anbd return\n",
    "        out2 = self.fc2(act1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass on our shallow neural network\n",
    "\n",
    "Let us start by initializing a neural network model, with 784 input nodes, 128 hidden nodes, and 10 output nodes. It is then transferring the model to a device, which could be a CPU or a GPU.\n",
    "\n",
    "Next, the code is getting a single sample from the train_loader iterator and assigning it to the variables data and target. This can be simply done with the next and iter functions. It is then printing the shape of data and target, and then selecting the first element of each and transferring them to the device (cpu or gpu).\n",
    "\n",
    "Finally, the code is performing a forward pass through the model by calling it on data1 and storing the output in the variables out2, which is then printed. \n",
    "\n",
    "Finally, we will apply the softmax operation as the final operation at the end of the forward method. Pytorch offers functional implementation of the softmax, as:\n",
    "\n",
    "```\n",
    "act2 =  torch.nn.functional.softmax(out2, dim = 1)\n",
    "```\n",
    "\n",
    "We can verify that it consists of values summing up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([[ 0.2566,  0.3706,  0.0477,  0.4794, -0.7680,  0.0566,  0.0520,  0.0036,\n",
      "         -0.1243, -0.0929]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1199, 0.1344, 0.0973, 0.1498, 0.0430, 0.0982, 0.0977, 0.0931, 0.0819,\n",
      "         0.0845]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = ShallowNeuralNet(n_x = 784, \\\n",
    "                         n_h = 128, \\\n",
    "                         n_y = 10).to(device)\n",
    "\n",
    "# Get a single sample\n",
    "sample = next(iter(train_loader))\n",
    "data, target = sample\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "data1 = data[0].to(device)\n",
    "target1 = target[0].to(device)\n",
    "print(data1.shape)\n",
    "print(target1)\n",
    "\n",
    "# Forward pass\n",
    "out2 = model(data1)\n",
    "act2 = torch.nn.functional.softmax(out2, dim = 1)\n",
    "print(out2)\n",
    "print(act2)\n",
    "print(act2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our shallow neural network\n",
    "\n",
    "As before,  the number of neurons in the input layer is specified by n_x, the number of neurons in the hidden layer is specified by n_h, and the number of neurons in the output layer is specified by n_y.\n",
    "\n",
    "The model is constructed with these three arguments, and then it is moved to the specified device (either GPU or CPU) using the to() method.\n",
    "\n",
    "Note that we have removed the softmax operation from the forward method. This is normal as the softmax operation will be used in the loss function, cross_entropy, which will be used in the trainer() function later.\n",
    "\n",
    "Speaking of, in the case of the binary classification, we used the following loss function, namely the **log-likelihood function**.\n",
    "\n",
    "$$ \\begin{array}{ll} L(x, y) & = \\displaystyle \\frac{-1}{N} \\sum_{k = 1}^N \\: y_k \\: ln\\big(p(x_k)\\big) \\: + \\: (1- y_k) \\: ln\\big(1 - p(x_k) \\big) \\end{array} $$\n",
    " \n",
    "But in the case of MNIST, we have more than two classes, so how does the loss function change now that we have 10 classes? The adjustment is actually quite simple, and the cross entropy loss function simply rewrites as shown below:\n",
    "\n",
    "$$ \\begin{array}{ll} L(x, y) & = \\displaystyle \\frac{-1}{N} \\sum_{k = 1}^N \\sum_{i = 0}^{9} \\: y_k^i \\: ln\\big( p_i(x_k) \\big) \\end{array} $$\n",
    "\n",
    "In the formula above, $ p_i(x_k) $ denotes the probability of sample $ x_k $ of being of class $ i $. In other words, it is the $i$-th value of the output vector produced by the model for sample $ x_k $ after softmax has been applied. The value $ y_k^i $ is the ground truth value for sample $ x_k $. For instance, if the sample $ x_k $ is of class 2, we have:\n",
    "\n",
    "$$ Y_k = (y_k^0, y_k^1, y_k^2, y_k^3, ... y_k^9) = (0, 0, 1, 0, ..., 0). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_y):\n",
    "        super().__init__()\n",
    "        # Define two layers using the nn.Linear()\n",
    "        self.fc1 = torch.nn.Linear(n_x, n_h)\n",
    "        self.fc2 = torch.nn.Linear(n_h, n_y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten images (transform them from 28x28 2D matrices to 784 1D vectors)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # First Wx + b operation\n",
    "        out1 = self.fc1(x)\n",
    "        # Using ReLU operation as activation after first layer\n",
    "        act1 = torch.relu(out1)\n",
    "        # Second Wx + b operation\n",
    "        out2 = self.fc2(act1)\n",
    "        # Careful: Softmax is not needed!\n",
    "        # (It will be used in cross entropy loss automatically)\n",
    "        # Therefore, return directly\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer is an instance of the Adam optimizer from PyTorch's torch.optim package, which is being used to optimize the model's parameters. The learning rate for the optimizer is specified by the lr argument, which is set to 1e-3 (0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train the neural network for 10 iterations (or epochs), as shown below.\n",
    "\n",
    "In addition, let us introduce a new good practice. In PyTorch, model.eval() sets the model to evaluation mode, which turns off certain features of certain special layers, such as dropout and batch normalization (which will be discussed next week). This is useful when you want to evaluate the model's performance on a dataset or make predictions using the model.\n",
    "\n",
    "To set the model back to training mode, you can use model.train(). This will enable features such as dropout and batch normalization, which are typically used during training to improve the model's generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShallowNeuralNet(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = ShallowNeuralNet(n_x = 784, n_h = 64, n_y = 10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "# Set model in train mode!\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [50/235], Loss: 0.4433\n",
      "Epoch [1/5], Step [100/235], Loss: 0.3628\n",
      "Epoch [1/5], Step [150/235], Loss: 0.3620\n",
      "Epoch [1/5], Step [200/235], Loss: 0.4224\n",
      "Epoch [1/5], Step [235/235], Loss: 0.2872\n",
      "Epoch [2/5], Step [50/235], Loss: 0.1535\n",
      "Epoch [2/5], Step [100/235], Loss: 0.2378\n",
      "Epoch [2/5], Step [150/235], Loss: 0.3072\n",
      "Epoch [2/5], Step [200/235], Loss: 0.2144\n",
      "Epoch [2/5], Step [235/235], Loss: 0.0885\n",
      "Epoch [3/5], Step [50/235], Loss: 0.1245\n",
      "Epoch [3/5], Step [100/235], Loss: 0.1748\n",
      "Epoch [3/5], Step [150/235], Loss: 0.1261\n",
      "Epoch [3/5], Step [200/235], Loss: 0.1601\n",
      "Epoch [3/5], Step [235/235], Loss: 0.1221\n",
      "Epoch [4/5], Step [50/235], Loss: 0.1483\n",
      "Epoch [4/5], Step [100/235], Loss: 0.1158\n",
      "Epoch [4/5], Step [150/235], Loss: 0.1991\n",
      "Epoch [4/5], Step [200/235], Loss: 0.0973\n",
      "Epoch [4/5], Step [235/235], Loss: 0.0532\n",
      "Epoch [5/5], Step [50/235], Loss: 0.0840\n",
      "Epoch [5/5], Step [100/235], Loss: 0.1421\n",
      "Epoch [5/5], Step [150/235], Loss: 0.1260\n",
      "Epoch [5/5], Step [200/235], Loss: 0.0879\n",
      "Epoch [5/5], Step [235/235], Loss: 0.0392\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Go trough all samples in train dataset\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Get from dataloader and send to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Compute loss\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Display\n",
    "        if (i+1) % 50 == 0 or i == 234:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation after training, Accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model accuracy on test after training\n",
    "# Set model in eval mode!\n",
    "model.eval()\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Get images and labels from test loader\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass and predict class using max\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Check if predicted class matches label\n",
    "        # and count numbler of correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "# Compute final accuracy and display\n",
    "accuracy = correct/total\n",
    "print(f'Evaluation after training, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Shallow to Deep Neural Networks and the need for custom layers\n",
    "\n",
    "It is now time for us to define and train our first Deep Neural Network.\n",
    "\n",
    "By definition, our deep neural network here consists of four layers: three dense layers with ReLU activation, followed by one dense layer with softmax activation.\n",
    "\n",
    "The sizes for each layer will decrease progressively to eventually produce n_y = 10 features at the output of the overall network. In general, it is good practice to have the size decrease by a factor 2 from one layer to another. For instance, we decide here, to have\n",
    "- the first layer receive an input of size 784 and produce an output of size 80,\n",
    "- the second layer receive an input of size 80 and produce an output of size 80,\n",
    "- the third layer receive an input of size 40 and produce an output of size 40,\n",
    "- and the fourth layer receive an input of size 20 and produce an output of size 10.\n",
    "\n",
    "The DenseReLU class below is a custom PyTorch module that consists of a linear layer (nn.Linear(n_x, n_y)) followed by a ReLU activation function (torch.relu()). The DenseNoRELU class is similar, but it applies no activation function after the linear layer. \n",
    "\n",
    "The DeepNeuralNet class represents the overall deep neural network. It initializes the four layers defined in DenseReLU and DenseSoftmax, and combines them into a single PyTorch sequential model using torch.nn.Sequential(). The forward pass of the network is then defined in the forward method: the input is first flattened from a 2D image to a 1D vector, and then passed through the combined layers using the (combined_layers)(x) notation.\n",
    "\n",
    "This modular approach, which defines blocks or layers and eventually assembles them in a larger network is very common in deep neural networks, especially when the architectures are very heavy and include many layers.\n",
    "\n",
    "**Important note:** You have probably realized that the softmax operation has disappeared, for the same reason as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseReLU(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_y):\n",
    "        super().__init__()\n",
    "        # Define Linear layer using the nn.Linear()\n",
    "        self.fc = torch.nn.Linear(n_x, n_y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Wx + b operation\n",
    "        # Using ReLU operation as activation after\n",
    "        return torch.relu(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNoReLU(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_y):\n",
    "        super().__init__()\n",
    "        # Define Linear layer using the nn.Linear()\n",
    "        self.fc = torch.nn.Linear(n_x, n_y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Wx + b operation\n",
    "        # No activation function\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_y):\n",
    "        super().__init__()\n",
    "        # Define three Dense + ReLU layers,\n",
    "        # followed by one Dense + Softmax layer\n",
    "        self.layer1 = DenseReLU(n_x, n_h[0])\n",
    "        self.layer2 = DenseReLU(n_h[0], n_h[1])\n",
    "        self.layer3 = DenseReLU(n_h[1], n_h[2])\n",
    "        self.layer4 = DenseNoReLU(n_h[2], n_y)\n",
    "        \n",
    "        # Combine all four layers\n",
    "        self.combined_layers = torch.nn.Sequential(self.layer1,\n",
    "                                                   self.layer2,\n",
    "                                                   self.layer3,\n",
    "                                                   self.layer4)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten images (transform them from 28x28\n",
    "        # 2D matrices to 784 1D vectors)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through all four layers\n",
    "        out = self.combined_layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we can, just like before train our deep neural network. The only part that changes is the n_h parameter in the initialization of the model, everything else remains the same.\n",
    "\n",
    "```\n",
    "model = DeepNeuralNet(n_x = 784, n_h = [80, 40, 20], n_y = 10).to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNet(\n",
       "  (layer1): DenseReLU(\n",
       "    (fc): Linear(in_features=784, out_features=80, bias=True)\n",
       "  )\n",
       "  (layer2): DenseReLU(\n",
       "    (fc): Linear(in_features=80, out_features=40, bias=True)\n",
       "  )\n",
       "  (layer3): DenseReLU(\n",
       "    (fc): Linear(in_features=40, out_features=20, bias=True)\n",
       "  )\n",
       "  (layer4): DenseNoReLU(\n",
       "    (fc): Linear(in_features=20, out_features=10, bias=True)\n",
       "  )\n",
       "  (combined_layers): Sequential(\n",
       "    (0): DenseReLU(\n",
       "      (fc): Linear(in_features=784, out_features=80, bias=True)\n",
       "    )\n",
       "    (1): DenseReLU(\n",
       "      (fc): Linear(in_features=80, out_features=40, bias=True)\n",
       "    )\n",
       "    (2): DenseReLU(\n",
       "      (fc): Linear(in_features=40, out_features=20, bias=True)\n",
       "    )\n",
       "    (3): DenseNoReLU(\n",
       "      (fc): Linear(in_features=20, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = DeepNeuralNet(n_x = 784, n_h = [80, 40, 20], n_y = 10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "# Set model in train mode!\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNeuralNet(\n",
      "  (layer1): DenseReLU(\n",
      "    (fc): Linear(in_features=784, out_features=80, bias=True)\n",
      "  )\n",
      "  (layer2): DenseReLU(\n",
      "    (fc): Linear(in_features=80, out_features=40, bias=True)\n",
      "  )\n",
      "  (layer3): DenseReLU(\n",
      "    (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      "  )\n",
      "  (layer4): DenseNoReLU(\n",
      "    (fc): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      "  (combined_layers): Sequential(\n",
      "    (0): DenseReLU(\n",
      "      (fc): Linear(in_features=784, out_features=80, bias=True)\n",
      "    )\n",
      "    (1): DenseReLU(\n",
      "      (fc): Linear(in_features=80, out_features=40, bias=True)\n",
      "    )\n",
      "    (2): DenseReLU(\n",
      "      (fc): Linear(in_features=40, out_features=20, bias=True)\n",
      "    )\n",
      "    (3): DenseNoReLU(\n",
      "      (fc): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [25/235], Loss: 2.2535\n",
      "Epoch [1/10], Step [50/235], Loss: 2.1548\n",
      "Epoch [1/10], Step [75/235], Loss: 2.0212\n",
      "Epoch [1/10], Step [100/235], Loss: 1.8771\n",
      "Epoch [1/10], Step [125/235], Loss: 1.6757\n",
      "Epoch [1/10], Step [150/235], Loss: 1.5283\n",
      "Epoch [1/10], Step [175/235], Loss: 1.2645\n",
      "Epoch [1/10], Step [200/235], Loss: 1.1419\n",
      "Epoch [1/10], Step [225/235], Loss: 0.9481\n",
      "Epoch [2/10], Step [25/235], Loss: 0.7601\n",
      "Epoch [2/10], Step [50/235], Loss: 0.6801\n",
      "Epoch [2/10], Step [75/235], Loss: 0.6530\n",
      "Epoch [2/10], Step [100/235], Loss: 0.5392\n",
      "Epoch [2/10], Step [125/235], Loss: 0.5538\n",
      "Epoch [2/10], Step [150/235], Loss: 0.5272\n",
      "Epoch [2/10], Step [175/235], Loss: 0.5655\n",
      "Epoch [2/10], Step [200/235], Loss: 0.4626\n",
      "Epoch [2/10], Step [225/235], Loss: 0.4788\n",
      "Epoch [3/10], Step [25/235], Loss: 0.3915\n",
      "Epoch [3/10], Step [50/235], Loss: 0.4326\n",
      "Epoch [3/10], Step [75/235], Loss: 0.3405\n",
      "Epoch [3/10], Step [100/235], Loss: 0.4491\n",
      "Epoch [3/10], Step [125/235], Loss: 0.4246\n",
      "Epoch [3/10], Step [150/235], Loss: 0.4788\n",
      "Epoch [3/10], Step [175/235], Loss: 0.4339\n",
      "Epoch [3/10], Step [200/235], Loss: 0.3479\n",
      "Epoch [3/10], Step [225/235], Loss: 0.3037\n",
      "Epoch [4/10], Step [25/235], Loss: 0.3945\n",
      "Epoch [4/10], Step [50/235], Loss: 0.3132\n",
      "Epoch [4/10], Step [75/235], Loss: 0.3945\n",
      "Epoch [4/10], Step [100/235], Loss: 0.3568\n",
      "Epoch [4/10], Step [125/235], Loss: 0.3336\n",
      "Epoch [4/10], Step [150/235], Loss: 0.3474\n",
      "Epoch [4/10], Step [175/235], Loss: 0.4292\n",
      "Epoch [4/10], Step [200/235], Loss: 0.3323\n",
      "Epoch [4/10], Step [225/235], Loss: 0.3167\n",
      "Epoch [5/10], Step [25/235], Loss: 0.4503\n",
      "Epoch [5/10], Step [50/235], Loss: 0.2998\n",
      "Epoch [5/10], Step [75/235], Loss: 0.3270\n",
      "Epoch [5/10], Step [100/235], Loss: 0.3025\n",
      "Epoch [5/10], Step [125/235], Loss: 0.4101\n",
      "Epoch [5/10], Step [150/235], Loss: 0.3185\n",
      "Epoch [5/10], Step [175/235], Loss: 0.2968\n",
      "Epoch [5/10], Step [200/235], Loss: 0.2410\n",
      "Epoch [5/10], Step [225/235], Loss: 0.2373\n",
      "Epoch [6/10], Step [25/235], Loss: 0.2500\n",
      "Epoch [6/10], Step [50/235], Loss: 0.3217\n",
      "Epoch [6/10], Step [75/235], Loss: 0.3212\n",
      "Epoch [6/10], Step [100/235], Loss: 0.2547\n",
      "Epoch [6/10], Step [125/235], Loss: 0.3237\n",
      "Epoch [6/10], Step [150/235], Loss: 0.2658\n",
      "Epoch [6/10], Step [175/235], Loss: 0.2901\n",
      "Epoch [6/10], Step [200/235], Loss: 0.2755\n",
      "Epoch [6/10], Step [225/235], Loss: 0.2156\n",
      "Epoch [7/10], Step [25/235], Loss: 0.2580\n",
      "Epoch [7/10], Step [50/235], Loss: 0.2151\n",
      "Epoch [7/10], Step [75/235], Loss: 0.3626\n",
      "Epoch [7/10], Step [100/235], Loss: 0.3359\n",
      "Epoch [7/10], Step [125/235], Loss: 0.2000\n",
      "Epoch [7/10], Step [150/235], Loss: 0.2065\n",
      "Epoch [7/10], Step [175/235], Loss: 0.2808\n",
      "Epoch [7/10], Step [200/235], Loss: 0.2426\n",
      "Epoch [7/10], Step [225/235], Loss: 0.2225\n",
      "Epoch [8/10], Step [25/235], Loss: 0.2400\n",
      "Epoch [8/10], Step [50/235], Loss: 0.3024\n",
      "Epoch [8/10], Step [75/235], Loss: 0.2822\n",
      "Epoch [8/10], Step [100/235], Loss: 0.2659\n",
      "Epoch [8/10], Step [125/235], Loss: 0.2483\n",
      "Epoch [8/10], Step [150/235], Loss: 0.2371\n",
      "Epoch [8/10], Step [175/235], Loss: 0.2187\n",
      "Epoch [8/10], Step [200/235], Loss: 0.2501\n",
      "Epoch [8/10], Step [225/235], Loss: 0.2892\n",
      "Epoch [9/10], Step [25/235], Loss: 0.2531\n",
      "Epoch [9/10], Step [50/235], Loss: 0.1837\n",
      "Epoch [9/10], Step [75/235], Loss: 0.2161\n",
      "Epoch [9/10], Step [100/235], Loss: 0.2670\n",
      "Epoch [9/10], Step [125/235], Loss: 0.2477\n",
      "Epoch [9/10], Step [150/235], Loss: 0.2849\n",
      "Epoch [9/10], Step [175/235], Loss: 0.2044\n",
      "Epoch [9/10], Step [200/235], Loss: 0.2179\n",
      "Epoch [9/10], Step [225/235], Loss: 0.2884\n",
      "Epoch [10/10], Step [25/235], Loss: 0.2101\n",
      "Epoch [10/10], Step [50/235], Loss: 0.1900\n",
      "Epoch [10/10], Step [75/235], Loss: 0.1974\n",
      "Epoch [10/10], Step [100/235], Loss: 0.2506\n",
      "Epoch [10/10], Step [125/235], Loss: 0.2055\n",
      "Epoch [10/10], Step [150/235], Loss: 0.2076\n",
      "Epoch [10/10], Step [175/235], Loss: 0.2554\n",
      "Epoch [10/10], Step [200/235], Loss: 0.2046\n",
      "Epoch [10/10], Step [225/235], Loss: 0.2218\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Go trough all samples in train dataset\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Get from dataloader and send to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Compute loss\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Display\n",
    "        if (i+1) % 25 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation after training, test accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model accuracy on test after training\n",
    "# Set model in eval mode!\n",
    "model.eval()\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Get images and labels from test loader\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass and predict class using max\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Check if predicted class matches label\n",
    "        # and count numbler of correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "# Compute final accuracy and display\n",
    "accuracy = correct/total\n",
    "print(f'Evaluation after training, test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of layers/neurons vs overfitting tradeoff, and what's next?\n",
    "\n",
    "This raises a question: **what is the appropriate number of layers to use and how many neurons should we use on each layer?**\n",
    "\n",
    "As explored in Notebook 8 from W2, there is no fixed rule for how many layers should be used in a deep neural network. The number of layers, as well as the number of neurons in each layer, should be chosen based on the complexity of the task and the amount of available data.\n",
    "\n",
    "In general, deep neural networks with many layers (tens, hundreds or even thousands) can learn very complex patterns in data, but they also require a large amount of data and computational resources to train. If the network is too deep, it may also be prone to overfitting, which can hinder its generalization performance on unseen data.\n",
    "\n",
    "On the other hand, shallow networks with fewer layers may be easier to train and require less data, but they may not be able to learn as complex patterns and may not achieve as high performance on some tasks.\n",
    "\n",
    "Finding the optimal number of layers and the optimal architecture of a deep neural network is often a trade-off between model complexity, computational resources, and performance, and requires some experimentation and model selection.\n",
    "\n",
    "This is typically a good practice when it comes to training Deep Neural Networks and something we will investigate in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
