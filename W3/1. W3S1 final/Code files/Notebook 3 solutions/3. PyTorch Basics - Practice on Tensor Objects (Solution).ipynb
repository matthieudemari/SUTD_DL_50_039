{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PyTorch Basics - Practice on Tensor Objects (Solution)\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.0 (22/06/2023)\n",
    "\n",
    "**Requirements:**\n",
    "- Torch (tested on v2.0.1+cu118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Consider the tensor A below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.3424e-01, 5.3511e-01, 8.3021e-01, 1.2386e-01, 2.9321e-02, 5.4940e-01],\n",
      "        [3.8249e-01, 5.4626e-01, 4.6828e-01, 1.7153e-02, 2.1382e-02, 3.6643e-01],\n",
      "        [2.0535e-01, 1.9226e-01, 3.5434e-01, 2.1795e-01, 1.0574e-04, 1.4056e-01],\n",
      "        [6.0028e-01, 5.6578e-01, 9.4895e-02, 9.6953e-02, 3.7144e-01, 2.6844e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Generating a random tensor, using seed for reproducibility\n",
    "torch.manual_seed(17)\n",
    "A = torch.rand(4, 6)\n",
    "# This should print\n",
    "# tensor([[4.3424e-01, 5.3511e-01, 8.3021e-01, 1.2386e-01, 2.9321e-02, 5.4940e-01],\n",
    "#        [3.8249e-01, 5.4626e-01, 4.6828e-01, 1.7153e-02, 2.1382e-02, 3.6643e-01],\n",
    "#        [2.0535e-01, 1.9226e-01, 3.5434e-01, 2.1795e-01, 1.0574e-04, 1.4056e-01],\n",
    "#        [6.0028e-01, 5.6578e-01, 9.4895e-02, 9.6953e-02, 3.7144e-01, 2.6844e-02]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we will come up with our own manual implementation of the mean for this tensor A, averaging elements in each column. This is something that we could do using the built-in torch function mean(), as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: tensor([0.4056, 0.4599, 0.4369, 0.1140, 0.1056, 0.2708])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truth:\", A.mean(dim = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to come up with our own implementation for this function, using for loops, instead of the built-in torch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: write a function to calculate the empirical mean value of each column.\n",
    "def emp_mean(A):\n",
    "    # Create an empty 1D tensor with the size corresponding to the number of columns in A\n",
    "    val = torch.empty(A.shape[1]) \n",
    "    # Iterate over columns using a for loop\n",
    "    for i in range(A.shape[1]):\n",
    "        column_sum = 0\n",
    "        # Iterate over rows using a second for loop (sum and then divide by number of elements)\n",
    "        for j in range(A.shape[0]):\n",
    "            column_sum += A[j, i]\n",
    "        val[i] = column_sum / A.shape[0]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function: tensor([0.4056, 0.4599, 0.4369, 0.1140, 0.1056, 0.2708])\n",
      "Ground truth: tensor([0.4056, 0.4599, 0.4369, 0.1140, 0.1056, 0.2708])\n"
     ]
    }
   ],
   "source": [
    "# Testing your function\n",
    "print(\"Your function:\", emp_mean(A))\n",
    "# Grunt truth\n",
    "print(\"Ground truth:\", A.mean(dim = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Consider the tensor B below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 5, 1, 2, 0],\n",
      "        [9, 8, 3, 2, 5],\n",
      "        [2, 9, 2, 2, 1],\n",
      "        [3, 4, 9, 7, 2],\n",
      "        [6, 4, 3, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Generating a random tensor, using seed for reproducibility\n",
    "torch.manual_seed(17)\n",
    "B = torch.randint(0, 10, (5, 5))\n",
    "# This should print\n",
    "# tensor([[9, 5, 1, 2, 0],\n",
    "#        [9, 8, 3, 2, 5],\n",
    "#        [2, 9, 2, 2, 1],\n",
    "#        [3, 4, 9, 7, 2],\n",
    "#        [6, 4, 3, 3, 2]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we would like to find the indices at which the tensor B has values greater than 5.\n",
    "\n",
    "This can typically be done with a mask and the nonzero() built-in function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask: tensor([[ True, False, False, False, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [False,  True, False, False, False],\n",
      "        [False, False,  True,  True, False],\n",
      "        [ True, False, False, False, False]])\n",
      "Ground truth: tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [2, 1],\n",
      "        [3, 2],\n",
      "        [3, 3],\n",
      "        [4, 0]])\n"
     ]
    }
   ],
   "source": [
    "mask = B > 5\n",
    "print(\"Mask:\", mask)\n",
    "indices = torch.nonzero(mask)\n",
    "print(\"Ground truth:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to come up with our own implementation for this function, using for loops, instead of the built-in torch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: write a function to find the indices of a tensor where the value is greater than 5.\n",
    "def find_indices(B):\n",
    "    # Store the indices as lists in a list first\n",
    "    indices_list = []\n",
    "    for i in range(B.shape[0]):\n",
    "        for j in range(B.shape[1]):\n",
    "            if B[i, j] > 5:\n",
    "                indices_list.append([i, j])\n",
    "    # Convert the list of indices into a tensor\n",
    "    indices = torch.tensor(indices_list)  \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function: tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [2, 1],\n",
      "        [3, 2],\n",
      "        [3, 3],\n",
      "        [4, 0]])\n",
      "Ground truth: tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [2, 1],\n",
      "        [3, 2],\n",
      "        [3, 3],\n",
      "        [4, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Testing your function\n",
    "print(\"Your function:\", find_indices(B))\n",
    "# Grunt truth\n",
    "print(\"Ground truth:\", torch.nonzero(B > 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Consider the tensors C and D below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4342, 0.5351, 0.8302],\n",
      "        [0.1239, 0.0293, 0.5494],\n",
      "        [0.3825, 0.5463, 0.4683]])\n",
      "tensor([[1.7153e-02, 2.1382e-02, 3.6643e-01, 2.0535e-01],\n",
      "        [1.9226e-01, 3.5434e-01, 2.1795e-01, 1.0574e-04],\n",
      "        [1.4056e-01, 6.0028e-01, 5.6578e-01, 9.4895e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Generating random tensors, using seed for reproducibility\n",
    "torch.manual_seed(17)\n",
    "C = torch.rand(3, 3)\n",
    "D = torch.rand(3, 4)\n",
    "# This should print\n",
    "# tensor([[0.4342, 0.5351, 0.8302],\n",
    "#        [0.1239, 0.0293, 0.5494],\n",
    "#        [0.3825, 0.5463, 0.4683]])\n",
    "print(C)\n",
    "# This should print\n",
    "# tensor([[1.7153e-02, 2.1382e-02, 3.6643e-01, 2.0535e-01],\n",
    "#        [1.9226e-01, 3.5434e-01, 2.1795e-01, 1.0574e-04],\n",
    "#        [1.4056e-01, 6.0028e-01, 5.6578e-01, 9.4895e-02]])\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we would like to concatenate both C and D to produce a 3-by-6 tensor.\n",
    "\n",
    "This can typically be done with built-in functions, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: tensor([[4.3424e-01, 5.3511e-01, 8.3021e-01, 1.7153e-02, 2.1382e-02, 3.6643e-01,\n",
      "         2.0535e-01],\n",
      "        [1.2386e-01, 2.9321e-02, 5.4940e-01, 1.9226e-01, 3.5434e-01, 2.1795e-01,\n",
      "         1.0574e-04],\n",
      "        [3.8249e-01, 5.4626e-01, 4.6828e-01, 1.4056e-01, 6.0028e-01, 5.6578e-01,\n",
      "         9.4895e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate one next to the other\n",
    "concatenated = torch.cat((C, D), dim = 1)\n",
    "print(\"Ground truth:\", concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to come up with our own implementation for this function, using for loops, instead of the built-in torch functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: concatenate both C and D, side by side, to produce a 3-by-6 tensor.\n",
    "# We will not implement size checks to confirm that the concatenation is possible.\n",
    "# Leaving this as an extra challenge for students.\n",
    "def concatenate(C, D):\n",
    "    # Initialize an empty tensor with the desired final shape\n",
    "    reshaped = torch.empty(C.shape[0], C.shape[1] + D.shape[1])\n",
    "\n",
    "    # Iterate over the rows\n",
    "    for i in range(C.shape[0]):\n",
    "        # Iterate over the columns\n",
    "        for j in range(C.shape[1] + D.shape[1]):\n",
    "            if j < C.shape[1]:\n",
    "                reshaped[i, j] = C[i, j]\n",
    "            else:\n",
    "                reshaped[i, j] = D[i, j - C.shape[1]]\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function: tensor([[4.3424e-01, 5.3511e-01, 8.3021e-01, 1.7153e-02, 2.1382e-02, 3.6643e-01,\n",
      "         2.0535e-01],\n",
      "        [1.2386e-01, 2.9321e-02, 5.4940e-01, 1.9226e-01, 3.5434e-01, 2.1795e-01,\n",
      "         1.0574e-04],\n",
      "        [3.8249e-01, 5.4626e-01, 4.6828e-01, 1.4056e-01, 6.0028e-01, 5.6578e-01,\n",
      "         9.4895e-02]])\n",
      "Ground truth: tensor([[4.3424e-01, 5.3511e-01, 8.3021e-01, 1.7153e-02, 2.1382e-02, 3.6643e-01,\n",
      "         2.0535e-01],\n",
      "        [1.2386e-01, 2.9321e-02, 5.4940e-01, 1.9226e-01, 3.5434e-01, 2.1795e-01,\n",
      "         1.0574e-04],\n",
      "        [3.8249e-01, 5.4626e-01, 4.6828e-01, 1.4056e-01, 6.0028e-01, 5.6578e-01,\n",
      "         9.4895e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Testing your function\n",
    "print(\"Your function:\", concatenate(C, D))\n",
    "# Grunt truth\n",
    "print(\"Ground truth:\", torch.cat((C, D), dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional questions (answers not provided).\n",
    "\n",
    "In order to practice your PyTorch Tensor skills, you may try to manually implement your own version of typical algorithms we ran on lists/Numpy arrays in previous classes, using the basic operations on PyTorch tensors.\n",
    "For instance, try writing algorithms:\n",
    "- Finding the maximum, minimum, median values of a given tensor,\n",
    "- Transposing a given 2D tensor,\n",
    "- Sorting a given 1D tensor (using bubble sort, insertion sort, selection sort, quick sort, merge sort),\n",
    "- Generating a 1D array containing the first K Fibonacci numbers with K given,\n",
    "- Computing the determinant value of a 2D tensor, and its eigenvalues/eigenvectors,\n",
    "- Etc\n",
    "\n",
    "Later, you can check their performance times compared to their Numpy/PyTorch implementations when running them on both CPU and CUDA (if available).\n",
    "\n",
    "In which scenarios is it slower to implement said functions and run them on GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "\n",
    "In the next notebook, we will investigate how to implement the backpropagation mechanism using the PyTorch framework, and eventually use it to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
