{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using the Fast Gradient Sign Attack to Generate Attack Samples\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (11/03/2022)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.9.6)\n",
    "- Matplotlib (tested on v3.5.1)\n",
    "- Numpy (tested on v1.22.1)\n",
    "- Pillow (tested on v9.0.0)\n",
    "- Torch (tested on v1.10.1)\n",
    "- Torchvision (tested on v0.11.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future\n",
    "from __future__ import print_function\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is a fix to work around the \"User-agent\" issue \n",
    "# when downloading the MNIST dataset\n",
    "from six.moves import urllib\n",
    "opener_req = urllib.request.build_opener()\n",
    "opener_req.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform definition\n",
    "# (Basic: only convert image to torch tensor)\n",
    "tf = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset and dataloader\n",
    "# (For testing only, we will use a pre-trained model)\n",
    "ds = datasets.MNIST('./data', train = False, download = True, transform = tf)\n",
    "test_loader = torch.utils.data.DataLoader(ds, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a basic Neural Net for MNIST\n",
    "    - Two convolutions, into ReLU activations and dropouts after ReLU,\n",
    "    - Flattening,\n",
    "    - Fully connected, into ReLU activation and dropout after ReLU,\n",
    "    - Fully connected, into Log-Softmax.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv. 1\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        # Conv. 2\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        # Dropout for Conv. layers\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # FC 1\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        # FC 2\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv. 1 + ReLU + Dropout\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # Conv. 2 + ReLU + Dropout\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten\n",
    "        x = x.view(-1, 320)\n",
    "        # FC 1 + ReLU + Droupout \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        # FC 2 + Log-Softmax\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model = Net()\n",
    "pretrained_model = \"./mnist_model.data\"\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location = 'cpu'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model in evaluation mode\n",
    "# (Important, because we have dropout layers!)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Gradient Sign Method (FGSM) attack function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Get element-wise signs of each element of the data gradient\n",
    "    data_grad_sign = data_grad.sign()\n",
    "    \n",
    "    # Create the attack image by adjusting each pixel of the input image\n",
    "    eps_image = image + epsilon*data_grad_sign\n",
    "    \n",
    "    # Clipping eps_image to maintain pixel values into the [0, 1] range\n",
    "    eps_image = torch.clamp(eps_image, 0, 1)\n",
    "    \n",
    "    # Return\n",
    "    return eps_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing FGSM attacks on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epsilon):\n",
    "\n",
    "    # Counter for correct values (used for accuracy)\n",
    "    correct_counter = 0\n",
    "    \n",
    "    # List of successful adversarial samples\n",
    "    adv_examples_list = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for image, label in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor to force torch to\n",
    "        # keep track of the gradients of the image\n",
    "        # (Needed for the fgsm_attack() function!)\n",
    "        image.requires_grad = True\n",
    "\n",
    "        # Pass the image through the model\n",
    "        output = model(image)\n",
    "        # Get the index of the max log-probability\n",
    "        init_pred = output.max(1, keepdim = True)[1] \n",
    "\n",
    "        # If the initial prediction is wrong, do not bother attacking, skip current image\n",
    "        if init_pred.item() != label.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, label)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect gradients of image\n",
    "        data_grad = image.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        eps_image = fgsm_attack(image, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the epsilon image\n",
    "        output2 = model(eps_image)\n",
    "        # Get the index of the max log-probability\n",
    "        eps_pred = output2.max(1, keepdim = True)[1]\n",
    "\n",
    "        # Check for successful attack\n",
    "        # (Successful meaning eps_pred label different from init_pred)\n",
    "        if eps_pred.item() == label.item():\n",
    "            correct_counter += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            # (Maximal number of saved samples is set to 5)\n",
    "            if (epsilon == 0) and (len(adv_examples_list) < 5):\n",
    "                adv_ex = eps_image.squeeze().detach().cpu().numpy()\n",
    "                adv_examples_list.append((init_pred.item(), eps_pred.item(), adv_ex))\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            # (Maximal number of saved samples is set to 5)\n",
    "            if len(adv_examples_list) < 5:\n",
    "                adv_ex = eps_image.squeeze().detach().cpu().numpy()\n",
    "                adv_examples_list.append((init_pred.item(), eps_pred.item(), adv_ex))\n",
    "\n",
    "    # Calculate final accuracy for this epsilon value\n",
    "    final_acc = correct_counter/float(len(test_loader))\n",
    "    \n",
    "    # Display for progress\n",
    "    print(\"Epsilon: {} - Test Accuracy = {}/{} = {}\".format(epsilon, \\\n",
    "                                                            correct_counter, \\\n",
    "                                                            len(test_loader), \\\n",
    "                                                            final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3, .5]\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test() function for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (accuracies vs. epsilon values and adversarial samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "plt.figure(figsize = (10, 7))\n",
    "\n",
    "# Display accuracy vs. Epsilon values plot\n",
    "plt.plot(epsilons, accuracies, \"o-\")\n",
    "\n",
    "# Adjust x-axis and y-axis labels and ticks\n",
    "plt.yticks(np.arange(0, 1.1, step = 0.1))\n",
    "#plt.xticks(np.arange(0, .35, step = 0.05))\n",
    "plt.title(\"Accuracy vs. Epsilon value\")\n",
    "plt.xlabel(\"Epsilon value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "# Browse through epsilon values and adversarial examples\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons), len(examples[0]), cnt)\n",
    "        \n",
    "        # Remove x-axis and y-axis ticks from plot\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        \n",
    "        # Labels for y axis\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize = 14)\n",
    "            \n",
    "        # Labels for each image subplot\n",
    "        orig, adv, ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        \n",
    "        # Display image\n",
    "        plt.imshow(ex, cmap = \"gray\")\n",
    "        \n",
    "# Display full plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
