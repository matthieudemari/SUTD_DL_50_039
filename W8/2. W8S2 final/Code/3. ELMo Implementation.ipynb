{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4773ebbd",
   "metadata": {},
   "source": [
    "# 3. ELMo Implementation\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (29/08/2023)\n",
    "\n",
    "This notebook discusses a possible implementation of the ELMo language model architecture, which is based on the paper from Peters et al., \"Deep contextualized word representations\", 2018.\n",
    "\n",
    "https://arxiv.org/abs/1802.05365\n",
    "\n",
    "This code is not designed for running (did not even bother coming with imports for this), and training code (dataset, loss, trainer functions, etc.) is also not provided.\n",
    "\n",
    "This is just for illustrative purposes, as we do not expect students to train such heavy language models (costly in time and resources). The purpose of this notebook is also to show how we may design multiple classes of nn.Module and combine them together in a very sophisticated architecture.\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.11.4)\n",
    "- Matplotlib (tested on v3.7.2)\n",
    "- Numpy (tested on v1.25.2)\n",
    "- Torch (tested on v2.0.1+cu118)\n",
    "- We also strongly recommend setting up CUDA on your machine!\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd4e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27dc6f",
   "metadata": {},
   "source": [
    "### Character-level 1D-CNNs\n",
    "\n",
    "In this implementation of the Character-level convolutions, we have a succession of 1D-Conv layers (using Conv2d, but look at the kernel size), interleaved with some Max-Pooling. Eventually, we obtain a 128-length vector for representing words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821e5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharConv(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer to start with\n",
    "        self.char_embedding = nn.Embedding(CHAR_VOCAB_SIZE, CHAR_EMBED_DIM)\n",
    "        \n",
    "        # Some convolution layers\n",
    "        self.conv1 = nn.Conv2d(CHAR_EMBED_DIM, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(CHAR_EMBED_DIM, 2, (1, 2))\n",
    "        self.conv3 = nn.Conv2d(CHAR_EMBED_DIM, 4, (1, 3))\n",
    "        self.conv4 = nn.Conv2d(CHAR_EMBED_DIM, 8, (1, 4))\n",
    "        self.conv5 = nn.Conv2d(CHAR_EMBED_DIM, 16, (1, 5))\n",
    "        self.conv6 = nn.Conv2d(CHAR_EMBED_DIM, 32, (1, 6))\n",
    "        self.conv7 = nn.Conv2d(CHAR_EMBED_DIM, 64, (1, 7))\n",
    "        self.convs = [self.conv1, self.conv2, self.conv3, self.conv4,\n",
    "                      self.conv5, self.conv6, self.conv7,]\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Character-level convolution\n",
    "        # Starts with embeddings and some reshaping\n",
    "        x = self.char_embedding(x).permute(0,3,1,2)\n",
    "        # Go through all convolution layers\n",
    "        x = [conv(x) for conv in self.convs]\n",
    "        # Max Pooling\n",
    "        x = [F.max_pool2d(x_c, kernel_size = (1, x_c.shape[3])) for x_c in x]\n",
    "        # Concatenate/Squeeze into final vector\n",
    "        # Final vector will be of size (1, n_batch, concat_length)\n",
    "        x = [torch.squeeze(x_p, dim = 3) for x_p in x]\n",
    "        x = torch.hstack(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13fb7b",
   "metadata": {},
   "source": [
    "### Bi-Directional LSTMs\n",
    "\n",
    "A possible implementation of a Bi-LSTM is given below. Note that we show also how to repeat the forward and backward LSTMs multiple times if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba46b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        # To build a bi-directional LSTM, we will need a few LSTM layers\n",
    "        self.lstm_f1 = nn.LSTM(128, 128)\n",
    "        self.lstm_r1 = nn.LSTM(128, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.proj = nn.Linear(128, 64, bias = False)\n",
    "        self.lstm_f2 = nn.LSTM(64, 128)\n",
    "        self.lstm_r2 = nn.LSTM(64, 128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Note: we expect word embeddings of size 128 (as the result of the\n",
    "        # previous character-level CNN network!)\n",
    "        # input shape is then: (seq_len, batch_size, 128)\n",
    "        \n",
    "        # 1st LSTM layer - Forward feed LSTM + Dropout\n",
    "        x_f = x\n",
    "        o_f1, (h_f1, __) = self.lstm_f1(x_f)\n",
    "        o_f1 = self.dropout(o_f1)\n",
    "        \n",
    "        # 2nd LSTM layer - Backward feed LSTM + Dropout\n",
    "        x_r = x.flip(dims=[0])\n",
    "        o_r1, (h_r1, __) = self.lstm_r1(x_r)\n",
    "        o_r1 = self.dropout(o_r1)\n",
    "        h1 = torch.stack((h_f1, h_r1)).squeeze(dim = 1)\n",
    "        \n",
    "        # Assemble\n",
    "        x2_f = self.proj(o_f1 + x_f)\n",
    "        x2_r = self.proj(o_r1 + x_r)\n",
    "        \n",
    "        # If we want, we can repeat the bi-directional LSTM\n",
    "        # a second time (or more, if needed), as such.\n",
    "        _, (h_f2, __) = self.lstm_f2(x2_f)\n",
    "        _, (h_r2, __) = self.lstm_r2(x2_r)\n",
    "        h2 = torch.stack((h_f2, h_r2)).squeeze(dim = 1)\n",
    "        \n",
    "        # Return both\n",
    "        return h1, h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63dbcb",
   "metadata": {},
   "source": [
    "### Full model assembly\n",
    "\n",
    "Assembling previous blocks together, along with some highway layers in the middle for a smoother transition.\n",
    "\n",
    "We will not train this model, as it would require a massive dataset and heavy computation power.\n",
    "\n",
    "This notebook only serves to show what the implementation of said model could look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00eba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLangModel(nn.Module):\n",
    "\n",
    "    def __init__(self, char_cnn, bi_lstm):\n",
    "        \n",
    "        super(BiLangModel, self).__init__()\n",
    "        # Blocks to be used for the highway connection\n",
    "        self.highway = nn.Linear(128, 128)\n",
    "        self.transform = nn.Linear(128, 128)\n",
    "        \n",
    "        # Character level CNN model\n",
    "        self.char_cnn = char_cnn\n",
    "        \n",
    "        # Bi-LSTM model\n",
    "        self.bi_lstm = bi_lstm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 1. Character-level convolution\n",
    "        x = self.char_cnn(x).permute(2, 0, 1)\n",
    "        \n",
    "        # 2 Some Highway layers\n",
    "        h = self.highway(x)\n",
    "        t_gate = torch.sigmoid(self.transform(x))\n",
    "        c_gate = 1 - t_gate\n",
    "        x_ = h * t_gate + x * c_gate\n",
    "        \n",
    "        # 3. Bi-LSTM\n",
    "        x1, x2 = self.bi_lstm(x_)\n",
    "        \n",
    "        # Feel free to play around and have a look\n",
    "        # at the x, x1 and x2 vectors!\n",
    "        return x, x1, x2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
