{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273d70ab",
   "metadata": {},
   "source": [
    "# 2. DeConvolutional layers\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (29/08/2023)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.11.4)\n",
    "- Matplotlib (tested on v3.7.2)\n",
    "- Numpy (tested on v1.25.2)\n",
    "- Torch (tested on v2.0.1+cu118)\n",
    "- Torchvision (tested on v0.15.2+cu118)\n",
    "- We also strongly recommend setting up CUDA on your machine! (At this point, honestly, it is almost mandatory).\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5279fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99771cfc",
   "metadata": {},
   "source": [
    "### Standard 2D convolution\n",
    "\n",
    "A reminder on the Convolution operation and its uses in PyTorch (Week 4!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6d6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A standard 2D Convolution\n",
    "conv = nn.Conv2d(in_channels = 8, \\\n",
    "                 out_channels = 8, \\\n",
    "                 kernel_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d93485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 8, 64, 64)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bef76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fee3b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# A deconvolution layer\n",
    "convt = nn.ConvTranspose2d(in_channels = 8, \\\n",
    "                           out_channels = 8, \\\n",
    "                           kernel_size = 5, \\\n",
    "                           stride = 1, \\\n",
    "                           padding = 0)\n",
    "z = convt(y)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69784947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2133,  0.9451,  0.6360, -0.4604,  0.7948, -0.8061, -0.1847, -1.3328,\n",
      "        -0.1808, -1.0739, -1.6417, -1.2412,  0.0923,  0.6039, -0.0500, -0.1279,\n",
      "        -0.8010, -0.1615, -0.1000,  0.1384, -0.3364, -1.3305, -0.9345,  0.8287,\n",
      "         1.4294,  0.5951,  2.3185, -0.7704, -0.8324,  0.5986, -1.1574,  1.7374,\n",
      "        -1.6881, -0.3008, -0.6154,  0.2343, -0.1941, -0.3119, -0.0289,  0.3838,\n",
      "         0.7373,  0.6623, -2.1396, -0.0271, -0.4175, -1.4343,  0.8439,  0.2157,\n",
      "         1.0417, -1.1163, -0.8961,  0.0957,  0.7615, -0.8589,  0.3302, -0.2674,\n",
      "        -1.0732,  1.2360,  1.1314, -0.2813,  0.3658, -0.2774, -1.5723,  1.6217])\n",
      "tensor([ 0.0120,  0.0844, -0.0740, -0.2266,  0.0192,  0.1908, -0.2807, -0.0076,\n",
      "        -0.0616, -0.1471,  0.0246, -0.1456, -0.2602, -0.0888,  0.0191,  0.1369,\n",
      "         0.1079,  0.0168, -0.1784, -0.1328,  0.0763,  0.2243,  0.2169,  0.1084,\n",
      "         0.0739, -0.1493, -0.1720,  0.0251,  0.0109,  0.2454, -0.0413,  0.2044,\n",
      "        -0.0082,  0.1042,  0.1261,  0.1664, -0.1490,  0.1306,  0.1344, -0.0050,\n",
      "        -0.1157,  0.0124, -0.0343, -0.1106,  0.1282,  0.0235, -0.0820, -0.1397,\n",
      "         0.2774, -0.1767,  0.1397,  0.1915, -0.1028, -0.0435, -0.0077, -0.1403,\n",
      "        -0.1658,  0.0482,  0.1084, -0.1978,  0.0089, -0.0175, -0.1192, -0.0117],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Comparing the first line of x and z\n",
    "print(x[0, 0, 0])\n",
    "print(z[0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae96d9",
   "metadata": {},
   "source": [
    "### Deconvolution with padding, stride and output padding\n",
    "\n",
    "A simple example of how we could use the ConvTranspose2d operation, which implements the DeConvolution operation in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51c7e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# A deconvolution layer with padding\n",
    "convt = nn.ConvTranspose2d(in_channels = 16, \\\n",
    "                           out_channels = 8, \\\n",
    "                           kernel_size = 5, \\\n",
    "                           padding = 2)\n",
    "x = torch.randn(32, 16, 64, 64)\n",
    "y = convt(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4ba597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# A deconvolution layer with stride and padding\n",
    "convt = nn.ConvTranspose2d(in_channels = 16, \\\n",
    "                           out_channels = 8, \\\n",
    "                           kernel_size = 5, \\\n",
    "                           stride = 2, \\\n",
    "                           output_padding = 1, \\\n",
    "                           padding = 2)\n",
    "x = torch.randn(32, 16, 64, 64)\n",
    "y = convt(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e0cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
