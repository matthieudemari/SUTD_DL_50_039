{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866b19f8",
   "metadata": {},
   "source": [
    "# 5. Vanilla GAN on MNIST with FC layers\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (29/08/2023)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.11.4)\n",
    "- Matplotlib (tested on v3.7.2)\n",
    "- Numpy (tested on v1.25.2)\n",
    "- Torch (tested on v2.0.1+cu118)\n",
    "- Torchvision (tested on v0.15.2+cu118)\n",
    "- We also strongly recommend setting up CUDA on your machine! (At this point, honestly, it is almost mandatory).\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b1473",
   "metadata": {},
   "source": [
    "### Dataset and dataloader\n",
    "\n",
    "As seen many times before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transform to be applied to dataset\n",
    "# - Tensor conversion\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95021a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST train dataset\n",
    "mnist = torchvision.datasets.MNIST(root = './data/',\n",
    "                                   train = True,\n",
    "                                   transform = transform,\n",
    "                                   download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a457b",
   "metadata": {},
   "source": [
    "### Discriminator model as a set of FC layers\n",
    "\n",
    "Very similar to the Encoder in the Notebook 1, or any image processing model using FC layers really..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Dicriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, image_size):\n",
    "        # Init from nn.Module\n",
    "        super().__init__()\n",
    "        \n",
    "        # FC layers\n",
    "        self.D = nn.Sequential(nn.Linear(image_size, hidden_size),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "                               nn.Linear(hidden_size, hidden_size),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "                               nn.Linear(hidden_size, 1),\n",
    "                               nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.D(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2b44a",
   "metadata": {},
   "source": [
    "### Generator model as a set of FC layers\n",
    "\n",
    "Generator will be based on Linear layers, and will produce 1d vectors of size 784, matching the size of the MNIST samples after they have been flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04431258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_size, hidden_size, image_size):\n",
    "        # Init from nn.Module\n",
    "        super().__init__()\n",
    "        \n",
    "        # FC layers\n",
    "        self.G = nn.Sequential(nn.Linear(latent_size, hidden_size),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(hidden_size, hidden_size),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(hidden_size, image_size),\n",
    "                               nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.G(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c447cc",
   "metadata": {},
   "source": [
    "### Trainer function\n",
    "\n",
    "The trainer function will implement the interleaved training discussed in slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for model generation and training\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 300\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create discriminator model\n",
    "D = Dicriminator(hidden_size, image_size)\n",
    "D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator model\n",
    "G = Generator(latent_size, hidden_size, image_size)\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9af55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr = 0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History trackers for training curves\n",
    "# Keeping track of losses and accuracy scores\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)\n",
    "real_scores = np.zeros(num_epochs)\n",
    "fake_scores = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077c494",
   "metadata": {},
   "source": [
    "### Training a GAN is difficult (read me before running)\n",
    "\n",
    "**Note:** running the cell below (our trainer function) will take a long time!\n",
    "\n",
    "It is also sensitive to unlucky initialization (as discussed in class).\n",
    "\n",
    "This basically means that the models are not guaranteed to train well at all, as different values for the initial parameters could lead to two different outcomes for the interleaved training.\n",
    "\n",
    "This is what makes training a GAN extra difficult!\n",
    "\n",
    "Feel free to try seeding the models and using different seeds to see how they may converge to different results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069467d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        # 1. Flatten image\n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "        images = Variable(images)\n",
    "        \n",
    "        # 2. Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        real_labels = Variable(real_labels)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        fake_labels = Variable(fake_labels)\n",
    "        \n",
    "        \"\"\"\n",
    "        PART 1: TRAIN THE DISCRIMINATOR\n",
    "        \"\"\"\n",
    "\n",
    "        # 3. Compute BCE_Loss using real images\n",
    "        # Here, BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels = 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # 3.bis. Compute BCELoss using fake images\n",
    "        # Here, BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # First term of the loss is always zero since fake_labels = 0\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 4. Backprop and optimize for D\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \"\"\"\n",
    "        PART 2: TRAIN THE GENERATOR\n",
    "        \"\"\"\n",
    "\n",
    "        # 5. Generate fresh noise samples and produce fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # 6. We train G to maximize log(D(G(z))\n",
    "        # instead of minimizing log(1-D(G(z)))\n",
    "        # (Strictly equivalent but empirically better)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # 7. Backprop and optimize G\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        \"\"\"\n",
    "        PART 3: UPDATE STATISTICS FOR VISUALIZATION LATER\n",
    "        \"\"\"\n",
    "        \n",
    "        # 8. Update the losses and scores for mini-batches\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) \\\n",
    "            + d_loss.item()*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) \\\n",
    "            + g_loss.item()*(1./(i+1.))\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) \\\n",
    "            + real_score.mean().item()*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) \\\n",
    "            + fake_score.mean().item()*(1./(i+1.))\n",
    "        \n",
    "        # 9. Display\n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e17b8",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "As usual, show the training curves for losses and accuracies of both models, along with some images produced by the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2436479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display losses for both the generator and discriminator\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), d_losses, label = 'd loss')\n",
    "plt.plot(range(1, num_epochs + 1), g_losses, label = 'g loss')    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d250f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracy scores for both the generator and discriminator\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d301d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a few fake samples (5 of them) for visualization\n",
    "n_samples = 5\n",
    "z = torch.randn(n_samples, latent_size).to(device)\n",
    "z = Variable(z)\n",
    "fake_images = G(z)\n",
    "fake_images = fake_images.cpu().detach().numpy().reshape(n_samples, 28, 28)\n",
    "print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[0])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[1])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[2])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[3])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03abfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
