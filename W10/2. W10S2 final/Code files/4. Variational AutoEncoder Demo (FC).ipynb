{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2403114e",
   "metadata": {},
   "source": [
    "# 4. Variational AutoEncoder Demo (FC)\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (29/08/2023)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.11.4)\n",
    "- Matplotlib (tested on v3.7.2)\n",
    "- Numpy (tested on v1.25.2)\n",
    "- Torch (tested on v2.0.1+cu118)\n",
    "- Torchvision (tested on v0.15.2+cu118)\n",
    "- We also strongly recommend setting up CUDA on your machine! (At this point, honestly, it is almost mandatory).\n",
    "\n",
    "### Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69dfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02170e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA check\n",
    "CUDA = True\n",
    "device = \"cuda\" if (torch.cuda.is_available() and CUDA) else \"cpu\"\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028eb66",
   "metadata": {},
   "source": [
    "### Dataset and dataloaders\n",
    "\n",
    "As seen many times before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db55cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# - ToTensor\n",
    "# - Image Normalization\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2151db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train datasets/dataloaders\n",
    "train_set = torchvision.datasets.MNIST(root='./data', \\\n",
    "                                       train = True, \\\n",
    "                                       download = True, \\\n",
    "                                       transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, \\\n",
    "                                           batch_size = 32, \\\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144fa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test datasets/dataloaders\n",
    "test_set = torchvision.datasets.MNIST(root = './data', \\\n",
    "                                      train = False, \\\n",
    "                                      download = True, \\\n",
    "                                      transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, \\\n",
    "                                          batch_size = 4, \\\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fdad0",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Conv2d and ConvTranspose2d layers used for encoder and decoder parts, linear layers for mean and variance computation and sampling method added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07a642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Variational AutoEncoder Model for MNIST\n",
    "class MNIST_VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, init_channels, kernel_size, latent_dim):\n",
    "        super().__init__()\n",
    " \n",
    "        # Encoder with stacked Conv\n",
    "        self.enc1 = nn.Conv2d(image_channels, init_channels, kernel_size, \\\n",
    "                              stride = 2, padding = 1)\n",
    "        self.enc2 = nn.Conv2d(init_channels, init_channels*2, kernel_size, \\\n",
    "                              stride = 2, padding = 1)\n",
    "        self.enc3 = nn.Conv2d(init_channels*2, init_channels*4, kernel_size, \\\n",
    "                              stride = 2, padding = 1)\n",
    "        self.enc4 = nn.Conv2d(init_channels*4, 64, kernel_size, \\\n",
    "                              stride = 2, padding = 0)\n",
    "        \n",
    "        # FC layers for learning representations\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, 64)\n",
    "        \n",
    "        # Decoder, simply mirroring the encoder with ConvTranspose\n",
    "        self.dec1 = nn.ConvTranspose2d(64, init_channels*8, kernel_size, \\\n",
    "                                       stride = 1, padding = 0)\n",
    "        self.dec2 = nn.ConvTranspose2d(init_channels*8, init_channels*4, kernel_size, \\\n",
    "                                       stride = 2, padding = 1)\n",
    "        self.dec3 = nn.ConvTranspose2d(init_channels*4, init_channels*2, kernel_size, \\\n",
    "                                       stride = 2, padding = 1)\n",
    "        self.dec4 = nn.ConvTranspose2d(init_channels*2, image_channels, kernel_size, \\\n",
    "                                       stride = 2, padding = 1)\n",
    "        \n",
    "        \n",
    "    def sample(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        mu: mean from the encoder's latent space\n",
    "        log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        \n",
    "        # Standard deviation\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        \n",
    "        # randn_like is used to produce a vector with same dimensionality as std\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # Sampling\n",
    "        sample = mu + (eps * std)\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encoder\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        \n",
    "        # Pooling\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        \n",
    "        # FC layers to get mu and log_var (mean and log-variance)\n",
    "        hidden = self.fc1(x)\n",
    "        mu = self.fc_mu(hidden)\n",
    "        log_var = self.fc_log_var(hidden)\n",
    "        \n",
    "        # Get the latent vector through reparameterization\n",
    "        z = self.sample(mu, log_var)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(-1, 64, 1, 1)\n",
    " \n",
    "        # Decoding\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = torch.sigmoid(self.dec4(x))\n",
    "        return x, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8038c",
   "metadata": {},
   "source": [
    "### Training function?\n",
    "\n",
    "Open question: how would we train such a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635bfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
